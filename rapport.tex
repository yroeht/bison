%\documentclass[a4paper,11pt,final]{article}
% Pour une impression recto verso, utilisez plutôt ce documentclass :
\documentclass[a4paper,11pt,twoside,final]{article}

\usepackage[english,francais]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[pdftex]{graphicx}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage[french]{varioref}
\usepackage{changepage} %for changing margins in appendices
\usepackage{gantt}

\usepackage{fancyhdr}
\usepackage{lastpage}
\pagestyle{fancy}

\newcommand{\reporttitle}{Rapport de stage}     % Titre
\newcommand{\reportauthor}{Théophile \textsc{Ranquet}} % Auteur
\newcommand{\reportsubject}{Stage de fin de Tronc Commun} % Sujet
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\setlength{\parskip}{1ex} % Espace entre les paragraphes

\hypersetup{pdftitle={\reporttitle},
            pdfauthor={\reportauthor},
            pdfsubject={\reportsubject},
            pdfkeywords={rapport} {vos} {mots} {clés}
}

\begin{document}
  \pagenumbering{roman}
  \include{title}
  \cleardoublepage % Dans le cas du recto verso, ajoute une page blanche si besoin
  \tableofcontents % Table des matières
  \sloppy          % Justification moins stricte : des mots ne dépasseront pas des paragraphes
  \cleardoublepage

  \pagenumbering{arabic}
  \setcounter{page}{1}
  \section*{Introduction} % Pas de numérotation
  \addcontentsline{toc}{section}{Introduction} % Ajout dans la table des matières

  Le stage de 2ème année du cycle d'ingénieur de l'EPITA, aussi appelé stage
  de fin de Tronc Commun, est une expérience critique dans le parcours de
  chacun. On pourrait en dire autant de tout stage, mais celui-ci est le
  dernier avant le stage de fin d'études, qui est un peu différent des autres
  en cela qu'il constitue une sorte de « période d'essai » par les entreprises
  et débouche dans 90\% des cas (chiffres officiels de l'école en 2010) sur une
  embauche (CDI, etc.). Ce stage de fin de tronc commun est donc de fait la
  dernière occasion de découvrir un potentiel métier avant la sortie de
  l'école, et il n'est pas rare que les étudiants choisissent de passer ces
  cinq mois dans un environnement qui n'est pas forcément celui auquel ils se
  destinaient pour leur avenir proche à la fin de leurs études, dans le but de
  s'assurer qu'ils ont fait le bon choix, ou éventuellement de voir si un coup
  de cœur ne les ferait pas changer d'avis.

  Ce stage se place avant les deux semestres de spécialisation des étudiants de
  l'EPITA\@. En ce qui me concerne, j'envisageais avant ce stage de m'orienter
  vers la majeure « Système, Réseau et Sécurité » (SRS). Du coup, il me fallait
  trouver un stage qui me plaise, mais qui me donne une expérience que je
  n'aurai pas forcément l'occasion de reproduire dans un an. Alliant mes
  intérêts pour la programmation Unix en C et C++ d'un côté, et pour
  la théorie des langages et la compilation de l'autre, c'est donc avec un
  naturel relatif que m'est venu l'idée de ce stage.

  Le sujet de ce stage est « contribution aux développements de GNU Bison et
  Tiger », et le lieu est le Laboratoire de Recherche et de Développement de
  l'EPITA (LRDE). C'est un cadre très différent de celui de mon précédent
  stage, et j'espérai par cela pouvoir gagner en maturité quand à la question
  de savoir quel type d'entreprise ou équipe je compte rejoindre à la fin de
  ma scolarité.

  Ce stage, en plus de m'avoir donné la chance de travailler avec excellent
  mentor, m'a permis de travailler avec des technologies auxquelles je n'étais
  pas forcément familier au premier abord, et de contribuer à un projet libre.
  Cela peut paraître anodin, mais c'est en fait tout un savoir faire qu'il faut
  acquérir. J'ai donc gagné avec ce stage un certain nombre de connaissances
  techniques, mais aussi toute une méthodologie qui, pour être tout à fait
  honnête, n'était pas forcément ce par quoi je brillais le plus. J'ai
  également consolidé certaines de mes notions d'informatique fondamentale,
  notamment dans ce qui a trait à l'analyse syntaxique (plus spécifiquement
  l'analyse syntaxique LR avec anticipation) et aux automates associés.

  /* FIXME: 2 more pages. *

  \cleardoublepage
  \section{Présentation du laboratoire}
  \subsection{Présentation générale}

  Le LRDE est un laboratoire de recherche sous tutelle de l'École Pour
  l'Informatique et les Techniques Avancées (EPITA). Il est composé de 8
  chercheurs, 2 administratifs, 3 thésards et 6 étudiants-chercheurs fin 2010.
  Son financement est couvert à 90\% par l'EPITA, le reste venant de contrats
  industriels et de projets académiques.  Appartenant à une école privée, le LRDE
  est une exception dans un monde où la recherche académique scientifique est
  quasi-exclusivement du ressort d'organismes publics.

  Historique Le LRDE a été créé en 1998 à l'initiative de Joël Courtois,
  directeur de l'EPITA, qui désirait équiper l'école d’un véritable laboratoire
  académique, tant pour attirer des enseignants de qualité que pour participer à
  la reconnaissance de l'école par ses pairs. En même temps le laboratoire
  permettrait aux meilleurs élèves de l'école de s'initier au monde de la
  recherche en participant à des projets de recherche.

  En 2005, sous l'impulsion du Conseil Scientifique tout juste crée, la
  nécessité est apparue de structurer le laboratoire autour de thématiques de
  recherche afin de permettre au laboratoire de percer dans le monde académique
  et industriel. La définition de cette thématique a été difficile à trouver.
  Le point commun le plus visible était, et l'est toujours, la programmation
  générique et performante. Il s’agit clairement de la marque de fabrique du
  laboratoire que l'on retrouve dans différents projets du laboratoire et a
  donné lieu à` une dizaine de publication. Aujourd'hui le séminaire du
  laboratoire porte sur cet aspect, mais ce type de programmation est un outil
  au service de projets de recherche qui sont les réelles activités principales
  des chercheurs. Parmi ces activités le traitement d'images était déjà la
  thématique la plus importante du laboratoire mais noyée parmi les autres.
  Aussi après un long processus de réflexion, le LRDE a retenu deux thématiques
  : Reconnaissance des formes, et Automates et vérification.

  \subsection{Les projets}

  Le LRDE a trois projets phares, trois bibliothèques génériques et
  performantes écrites en C++, toutes sous licence libre. Ces bibliothèques
  font partie intégrante de notre re- cherche et peuvent être utilisées dans la
  réalisation de projets et de prestations. Actuelle- ment seule Olena, la
  bibliothèque la plus ancienne du laboratoire et la plus avancée, est utilisée
  dans le cadre de projets et a permis d’obtenir des contrats industriels.

  \subsubsection{Olena – http://olena.lrde.epita.fr/}

  Olena est une plate-forme de traitement d’images générique et performante. Le
  but de cette bibliothèque est de permettre une écriture unique d’algorithmes
  sachant que les entrées de ces algorithmes peuvent être de différente nature.
  Ainsi les entrées possibles sont des images 1D (signaux), 2D (images
  classiques), 3D (volumes), ou des graphes et leurs généralisations (complexes
  cellulaires). De plus, les valeurs stockées dans ces images sont de types
  variés : booléens pour les images binaires, des niveaux de gris avec
  différents encodages, des flottants ou autres. La force d’Olena est de
  préserver la nature abstraite des algorithmes sans pour autant devoir
  sacrifier les performances.

  \subsubsection{Vaucanson – http://vaucanson.lrde.epita.fr/}

  On peut décomposer Vaucanson en trois gros morceaux :
  \begin{enumerate}
    \item Une bibliothèque générique, dans laquelle sont définis
      \begin{enumerate}
        \item différents types de représentation d’automates (graphes ou tables
          de hachage) et d'expressions rationnelles
        \item différents types de monoïdes et semi-anneaux
        \item différents algorithmes qui les manipulent
      \end{enumerate}
    \item Une interface en ligne de commande, appelée TAF-Kit, qui permet
      d’appeler les fonctionnalités principales de la bibliothèque sans devoir
      écrire de C++. Du fait de l'approche générique employée dans la
      bibliothèque, TAF-Kit doit être instanciée pour un type particulier
      (c’est-à-dire un choix de représentation d’automate, monoïde, et semi-
      anneau). Une douzaine de telles instances sont construites pour des types
      prédéfinis.
    \item Une interface graphique dont le développement a été repris par
      l'équipe du Pr. Hsu-Chun Yen à Taïwan.
  \end{enumerate}

  Cette bibliothèque est développée selon un paradigme de programmation
  générique permettant:
  \begin{itemize}
    \item d'écrire les algorithmes une seule fois, indépendamment de la
      structure de données utilisée pour représenter les automates ou les
      expressions rationnelles, et indépendamment du monoïde et du semi-anneau
      utilisé par cet objet.
    \item de ne pas payer le prix de cette abstraction pour être (en théorie)
      aussi rapide à l'exécution qu'un algorithme
  \end{itemize}

  \subsubsection{Spot – http://spot.lip6.fr/}
  Spot est une bibliothèque de \textit{model checking}. C’est-à-dire qu'elle
  offre des algorithmes utiles à la construction d'un \textit{model checker}
  travaillant suivant une approche par automate.  Par rapport aux autres
  outils, nous nous distinguons par l'utilisation d'automates généralisés avec
  conditions d'acceptation sur les transitions, alors que la plupart de la
  recherche est faite sur des automates non-généralisés avec conditions
  d’acceptation sur les états.  Les deux formalismes sont aussi expressifs,
  mais le premier est beaucoup plus concis et permet de réaliser les opérations
  de base de l'approche automate de façon plus efficace:

  \begin{enumerate}
    \item la traduction donne des automates plus compacts, donc le produit est
      (généralement) aussi plus petits
    \item l'utilisation de condition d’acceptation généralisées, permet
      notamment de représenter très facilement des hypothèses d'équité faible
    \item la recherche de circuit acceptant dans un automate généralisé peut se
      faire aussi rapidement que dans un automate non-généralisés.
  \end{enumerate}

  \subsection{Effectifs}

  L'effectif actuel comprend les chercheurs suivants :
  \begin{adjustwidth}{-2cm}{-2cm}
    \begin{center}
      \begin{tabular}{| l | c | l | l | l |}
        \hline
        Nome & Né en & Formation & Statut & Arrivée \\
        \hline
        Ala-Eddine Ben-Salem & 1980 & M2 SLCP (INP Toulouse) & Doctorant &
        2010 \\
        Ana Stefania Calarasanu & & M2 Paris VI & Doctorante & 2012 \\
        Edwin Caralinet & 1990 & EPITA / MVA ENS Cachan & Doctorant & 2012 \\
        Etienne Renault & & M2 Paris VI & Doctorant & 2011 \\
        Yongchao Xu & 1986 & M2 Paris XI & Doctorant & 2010 \\
        \hline
        Guillaume Lazarra & 1985 & EPITA & Ing.\ de recherche & 2008 \\
        \hline
        Réda Dehak  & 1975 & Dr ENST & MdC & 2002 \\
        Akim Demaille & 1970 & X / Dr ENST & MdC & 1999 \\
        Alexandre Duret-Lutz & 1978 & EPITA / Dr Paris VI & MdC & 2007 \\
        Jonathan Fabrizio & 1978 & Dr Paris VI & MdC & 2009 \\
        Thierry Géraud & 1969 & ENST / Dr ENST & MdC & 1998 \\
        Roland Levillain & 1980 & EPITA / M2 SIRF (ENST) & MdC & 2005 \\
        Olivier Ricou & 1966 & Dr Paris VI & MdE - Directeur & 2002 \\
        Didier Verna & 1970 & ENST / Dr ENST & MdC & 2000 \\
        \hline
      \end{tabular}
    \end{center}
  \end{adjustwidth}

  \subsection{La majeure CSI}

  La majeure Calcul Scientifique et Image (CSI) est orientée vers la recherche
  académique et permet à des étudiants de s'immerger dans un laboratoire aux
  côtés des enseignants chercheurs. Les thèmes de recherche vont du traitement
  d'images à la manipulation d'automates en passant par le traitement de la
  parole, le model-checking ou l'aide à la décision.

  L'ingénieur CSI se destine dans une première phase à la préparation d'une
  thèse, en France ou à l'étranger, et il rejoindra ensuite la communauté des
  chercheurs dans un cadre académique ou au sein des structures de recherche de
  grandes entreprises ou de start-up innovantes.\footnote{%
  http://www.epita.fr/cursus-cycle-ingenieur-majeures.aspx}

  Voici le sujet du travail des sept étudiants CSI de la promotion 2013 qui
  étaient à mes côtes pendant ce stage\footnote{%
  http://lrde.epita.fr/cgi-bin/twiki/view/Publications/Seminar-2013-01-16}:

  \subsubsection*{Spot: Réduction par simulation pour les TGBA (Thomas Badie)}

  L'approche par automates du model checking s'appuie traditionnellement sur
  des Automates de Büchi (BA) qu'on souhaite les plus petits possible. Spot,
  bibliothèque de model checking, utilise principalement des TGBA qui
  généralisent les BA\@. Nous avons déjà présenté une méthode de réduction par
  simulation (dite directe). Cette technique a permis de produire des automates
  plus petits que dans les précédentes versions.  La simulation consiste à
  fusionner les états ayant le même suffixe infini. Nous montrons que nous
  pouvons aussi fusionner ceux ayant le même préfixe infini (c'est la
  cosimulation). On peut répéter la simulation et la cosimulation pour créer la
  simulation itérée. Cette méthode est incluse dans Spot 1.0 et est une grande
  amélioration de la simulation.  On expérimente aussi une méthode qui consiste
  à modifier certaines conditions d'acceptations (appellées sans importances).
  Puisque celles qui sont sur les transitions entre composantes fortement
  connexes n'ont pas d'influence sur le langage, on peut les modifier pour
  aider la simulation.

  \subsubsection*{Spot: Méthodes de réduction par ordre partiel adaptatives
  (Pierre Parutto)}

  Le model checking explicite de systèmes concurrents souffre d'une croissance
  exponentielle du nombre d'états représentant un système.  Les méthodes de
  réduction par ordre partiel sont un ensemble de méthodes permettant de
  combattre ce problème. Celles-ci permettent d'ignorer les états redondants
  lors de la génération de l'espace d'états. Parmi elles, nous avons choisi les
  algorithmes two phase et ample set comme base pour nos investigations.
  Ceux-ci ont été implémentés dans Spot, la bibliothèque C++ de model checking
  développée au LRDE, en utilisant l'interface DiVine. En se basant sur ces
  méthodes et sur le fait que les algorithmes dans Spot sont calculés à la
  volée, nous avons défini une nouvelle classe de méthodes appelées méthodes de
  réduction par ordre partiel adaptatives. L'idée est de se baser sur l'état
  courant de l'automate de la formule et non sur la formule tout entière. Les
  résultats obtenus sur notre suite de tests montrent que cette méthode donne
  de meilleurs résultats que les
  méthodes d'ordre partiel classiques.

  \subsubsection*{Speaker ID: Spherical Discriminant Analysis (Victor Lenoir)}

  Le rôle de la vérification de locuteur est de vérifier l'identité présumée
  d'un segment de parole. Actuellement, les meilleures performances sont
  obtenues par un mapping de chaque segment de parole d'un locuteur vers un
  vecteur appelé I-vector. Le score de la vérification de locuteur est calculé
  par une distance cosine entre ces deux vecteurs représentant chacun un
  locuteur. Ce rapport décrit une technique de réduction de dimension appelée
  Spherical Discriminant Analysis (SDA). Les objectifs de cette projection sont
  de maximiser la distance cosinus entre deux locuteurs différents et de
  minimiser la distance cosinus entre deux même locuteurs; il a été montré que
  le sous-espace de la SDA, qui est plus approprié pour la distance cosinus que
  la Linear Discriminant Analysis (LDA), obtient de meilleures performances en
  reconnaissance faciale. Nous allons comparer les performances obtenues par la
  SDA avec celles obtenues par la LDA.

  \subsubsection*{Climb: Parallélisation de Climb (Laurent Senta)}

  Climb est une bibliothèque de traitement d'image générique développée en
  Common Lisp. Elle fournit une couche de généricité bas niveau utilisée pour
  définir de nouveaux algorithmes de traitement d'image. Il est aussi possible
  de créer des chaînes de traitements soit en utilisant un "Domain Specific
  Language" déclaratif ou bien à l'aide d'une interface graphique. Afin
  d'améliorer les performances de la bibliothèque, ces différents niveaux
  peuvent être parallélisés. Nous décrirons les différents aspects de ce
  processus de parallélisation. Pour chaque niveau, nous détaillons
  l'implémentation des traitements parallèles, leurs impacts sur
  l'utilisabilité de la bibliothèque ainsi que les gains de performance
  obtenus.

  \subsubsection*{Vaucanson: FSMXML pour Vaucanson 2.0 (David Moreira)}

  Vaucanson est une bibliothèque de manipulation d'automates et de
  transducteurs. La version 2.0 est aujourd'hui en cours de développement et le
  design a été revu pour avoir des parties statiques et dynamiques. Dans
  Vaucanson 1.4, les entrées/sorties utilisent intensivement le format XML
  spécifié par le groupe de Vaucanson, FSMXML\@. Mes travaux consistent à
  développer et rafraîchir des spécifications du format présent dans Vaucanson
  1.4. Cette mise à jour nous permet la sauvegarde et la lecture d'automates
  aux Weight Sets particuliers tels que des expressions rationnelles ou même
  des automates pondérés.

  \subsubsection*{Olena: Calcul du flux optique dans des séquences avec des
  parties manquantes (Sylvain Lobry)}

  Calculer le flux optique peut être un premier pas vers l'inpainting vidéo.
  Pour cette application, nous devons manipuler des séquences avec des zones
  manquantes, celles à inpainter. Le flux optique peut être calculé de manière
  locale ou globale. Les méthodes globales ont généralement de meilleurs
  résultats. Dans le cas de séquences avec des zones manquantes, les méthodes
  globales ne peuvent pas être utilisées de manière directe à cause du manque
  d'informations dans ces régions. Nous présentons une méthode combinant des
  algorithmes locaux et globaux afin de calculer le flux optique dans ce type
  de séquences ce qui nous permet d'inpainter efficacement et simplement des
  vidéos.

  \subsubsection*{Olena: Variational image inpainting by combination of features
  (Coddy Levi)}

  L'inpainting consiste à réparer des parties d'une image de façon visuellement
  plausible. Une catégorie de méthodes répondant à ce problème est basée sur
  des équations aux dérivées partielles (EDP). Cette approche consiste à
  propager itérativement des informations géométriques et d'intensités à
  l'intérieur des régions à réparer. Cependant l'élaboration de tels modèles
  demande une compréhension théorique du processus de diffusion souvent
  difficile à obtenir. Basé sur le papier de Risheng Liu traitant d'une
  approche ascendante à la composition de l'EDP par combinaison d'invariants
  simples, nous proposons une mise en oeuvre optimisée que nous comparons à
  l'existant.

  \subsection{Positionnement du stage au sein du laboratoire}

  Bison est un projet GNU, ce n'est pas un projet du laboratoire. Cependant,
  son mainteneur est Akim Demaille, membre permanent du LRDE\@. De part la
  nature du projet Bison\footnote{voir section suivante}, ce stage était très
  proche de la Théorie des Langages, qui n'est pas étrangère au LRDE non plus.

  Enfin, un des projets du LRDE est le compilateur Tiger\footnote{%
  http://www.lrde.epita.fr/~akim/ccmp/tiger.html}, qui utilise Bison, et
  une partie de mon travail visait très spécifiquement des fonctionnalités
  développées avant tout pour Tiger (car non publiées).

  \cleardoublepage

  \section{Le projet GNU Bison}

GNU Bison est l'implémentation de l'analyseur syntaxique yacc par le projet GNU.

  \subsection{Analyseurs syntaxiques}

  \subsection{Présentation de bison}

  \subsection{Age et volumétrie du projet}

  \cleardoublepage

  \section{Travail effectué}

  \subsection{Vue d'ensemble}

  Mon stage a débuté septembre 2012. Peu avant moi, en juin 2012, Victor
  Santet (EPITA promotion 2015) était venu y faire un mois de stage. Il est
  parti en laissant des bases intéressantes pour une poursuite du travail dans
  sa lancée. Le travail en question portait sur les avertissements et erreurs
  générés par Bison. J'ai donc commencé mon stage en continuant sur cette
  lancée, et ce pendant un mois. Cette tâche correspond à l'élément [1] dans le
  diagramme de Gantt fourni plus bas.


  La continuation a --là encore-- été guidé très largement par les suggestions
  de mon mentor.  Il y avait déjà une liste d'améliorations possibles maintenue
  dans un fichier TODO, ce fut une source d'inspiration assez facile pour
  débuter.

  C'est ainsi que la suite de mon travail porta sur une option non essentielle
  de Bison: \texttt{-{}-graph}, qui génère une visualisation de l'automate utilisé
  par l'analyseur généré. Ce graphe était relativement pauvre, et je l'ai donc
  enrichi. Suite à diverses complications, cette tâche pris environ un mois et
  demi. Cette phase de développement se découpa en deux phases bien distinctes,
  j'ai donc pris le soin de les séparer ci-après. Le lecteur les retrouvera aux
  indices [3] et [4].

  Vinrent à ce moment plusieurs nouvelles pistes d'amélioration, lancées par
  Akim. La première ([5]) était la résolution d'un "bug" (en fait c'est n'est
  pas vraiment un, comme je l'explique plus loin dans ce rapport) de longue
  date qui faisait que si l'utilisateur ne spécifiait pas d'argument
  supplémentaire pour l'interface de la fonction de rapport d'erreur alors dans
  certains squelettes les informations de localisation de l'erreur étaient
  absentes (mais dans d'autres si). La deuxième était une amélioration de
  l'affichage des erreurs ([2]). En effet, le choix avait été fait de respecter
  des conventions semblables à celles de GCC (\textit{GNU Compiler
  Collection}), et donc l'introduction récente de changements dans le rapport
  des erreurs par celui-ci méritait une imitation dans Bison. J'ai travaillé
  sur ces deux aspects là en parallèle (bien que, contrairement à ce qu'on
  pourrait croire en retenant que ces deux fonctionnalités portent sur les
  messages d'erreurs, celles-ci étaient tout à fait orthogonales).

  Ce fut alors le premier jalon de ce stage: la sortie de Bison 2.7, qui
  incluait mes contributions de ces 3 premiers mois de stage.

  Fort des connaissances acquises, je commençai alors à travailler sur les
  squelettes de Bison.

  /* FIXME: wrapper, locations, \ldots glr.cc [8] */

  J'implémentai alors quelques modifications au squelette LALR C++ ([9]) mais
  je me suis heurté à ce qu'on pourrait appeler un mur: le schéma utilisé pour
  représenter les symboles n'était pas du tout viable si on voulait envisager
  des améliorations du genre de ce que je proposais (et qui, honnêtement,
  paraissent maintenant bien mineures par rapport à l'avalanche de travail
  engendré par ce qui a suivi). On a donc du ensuite retravailler le
  fonctionnement des symboles ([10]).

  \begin{adjustwidth}{-4cm}{-2cm}
  \begin{gantt}[xunitlength=0.7cm,fontsize=\small,titlefontsize=\small,drawledgerline=true]{14}{20}
    \begin{ganttitle}
      \titleelement{2012}{16}
      \titleelement{2013}{4}
    \end{ganttitle}
    \begin{ganttitle}
      \numtitle{9}{1}{12}{4}
      \numtitle{1}{1}{1}{4}
    \end{ganttitle}
    \begin{ganttitle}
      \numtitle{1}{7}{22}{1}
      \numtitle{1}{7}{22}{1}
      \numtitle{1}{7}{22}{1}
      \numtitle{1}{7}{22}{1}
      \numtitle{1}{7}{22}{1}
    \end{ganttitle}
    \ganttbar{warnings as errors [1]}{1}{4}
    \ganttbarcon{caret diagnostics [2]}{10}{2}
    \ganttbar{show reductions -g [3]}{5}{2}
    \ganttbarcon{show reductions xslt [4]}{7}{4}
    \ganttbar{api.pure full [5]}{10}{2}
    \ganttmilestonecon{version 2.7 released}{14}
    \ganttbar[pattern=north east lines, color=red]{epita coding-style [6]}{12}{2}
    \ganttbar{leak hunting [7]}{13}{2}
    \ganttbar{glr.cc [8]}{15}{1}
    \ganttbarcon{lalr1.cc [9]}{16}{1}
    \ganttbarcon{symbols [10]}{17}{3}
  \end{gantt}
  \end{adjustwidth}

  \subsection{Erreurs et avertissements}

  Bison est un compilateur, il va donc tenter de construire un fichier en
  sortie à partir d'un fichier en donné en entrée par l'utilisateur. Du coup,
  rien ne garantit la validité de celui-ci. Il peut y avoir des informations
  manquantes ou incompatibles dans les données lues par Bison. De fait, les
  compilateurs sont des outils de travail avec lesquels l'utilisateur interagit
  beaucoup, et en pratique le développeur (qui est plus habitué à ce que les
  choses se passent mal que à ce qu'elles se passent bien) est d'ailleurs
  souvent plus intéressé par les problèmes rencontrés par le compilateur que
  par la sortie en assembleur elle-même: la gestion des erreurs est donc un
  aspect très important des compilateurs en général, et ceux-ci incluent Bison.

  La compatibilité avec YACC (c'est à dire le comportement décrit par l'IEEE
  1003\footnote{%
  http://pubs.opengroup.org/onlinepubs/009695399/utilities/yacc.html}) n'impose
  absolument rien sur l'affichage à produire dans le terminal en cas d'erreur.
  Le choix a donc été fait de suivre le comportement de GCC, qui distingue très
  nettement plusieurs catégories d'erreurs:

  \begin{itemize}
    \item \textit{warnings}, les simples avertissements à l'utilisateur. Ils
      indiquent que le compilateur a détecté quelque chose de suspect dans le
      code de l'utilisateur, potentiellement une erreur de sa part. Le
      programme peut tout de même continuer son exécution et produire un
      résultat plausible.
    \item \textit{complaints}, ou tout simplement \textit{errors}, les erreurs
      que le compilateur rencontre sur un bout du code de l'utilisateur. Le
      programme peut continuer à traiter le reste du code de l'utilisateur,
      et aller le plus loin possible dans son exécution avant d'être bloqué
      inconditionnellement. La compilation ne produit pas de fichier en sortie.
    \item \textit{fatal errors}, les erreurs pour lesquelles ça n'aurait aucun
      sens de continuer l'exécution plus loin. Le programme s'arrête
      immédiatement.
  \end{itemize}

  \vspace{0.5cm}

  Voici la façon dont GCC les signale, par exemple:

  \begin{verbatim}
test.c: In function ‘main’:
test.c:6:3: error: expected declaration or statement at end of input
test.c:4:9: warning: unused variable ‘ar’ [-Wunused-variable]
  \end{verbatim}

  On remarque que les messages commencent par \textit{error:} ou
  \textit{warning:} selon
  qu'il s'agisse d'une erreur ou d'un simple avertissement. On note également
  que les avertissement sont divisés en de nombreuses catégories. Par exemple,
  ici, l'avertissement est attaché à la catégorie \textit{unused-variable},
  comme indiqué en fin du message.
  Voici un extrait du manuel de GCC qui montre le type de catégories de qu'il
  existe:

  \begin{verbatim}
Warning Options
       -fsyntax-only  -fmax-errors=n  -pedantic -pedantic-errors -w -Wextra
       -Wall  -Waddress -Waggregate-return  -Warray-bounds -Wno-attributes
       -Wno-builtin-macro-redefined -Wc++-compat -Wc++11-compat -Wcast-align
       -Wcast-qual -Wchar-subscripts -Wclobbered  -Wcomment -Wconversion
       -Wcoverage-mismatch  -Wno-cpp -Wno-deprecated
  \end{verbatim}

  Ces options servent à activer les avertissements associés. Il est d'usage de
  n'en activer que quelques uns par défaut et de laisser à l'utilisateur le
  soin de sélectionner quelles catégories d'avertissements il veut que le
  compilateur lui rapporte, ainsi que lesquelles il veut au contraire qu'il
  ignore.

  Le travail de Victor, sur lequel je me suis basé, avait ajouté le support de
  cette organisation des avertissements de Bison en catégories, activables
  indépendamment.

  Voici un extrait du guide d'utilisation de Bison:

  \begin{verbatim}
Operation modes:
  -h, --help                 display this help and exit
  -V, --version              output version information and exit
      --print-localedir      output directory containing locale-dependent data
      --print-datadir        output directory containing skeletons and XSLT
  -y, --yacc                 emulate POSIX Yacc
  -W, --warnings[=CATEGORY]  report the warnings falling in CATEGORY

Warning categories include:
  `midrule-values'    unset or unused midrule values
  `yacc'              incompatibilities with POSIX Yacc
  `conflicts-sr'      S/R conflicts (enabled by default)
  `conflicts-rr'      R/R conflicts (enabled by default)
  `deprecated'        obsolete constructs
  `other'             all other warnings (enabled by default)
  `all'               all the warnings
  `no-CATEGORY'       turn off warnings in CATEGORY
  `none'              turn off all the warnings
  `error[=CATEGORY]'  treat warnings as errors
  \end{verbatim}

  Et voici une démonstration de leur usage (notez la ressemblance avec le
  comportement de GCC):

  \begin{verbatim}
  $ bison -Wdeprecated
  input.yy:2.9-15: warning: deprecated directive: ‘%define variant’, use
  ‘%define api.value.type variant’ [-Wdeprecated]
  input.yy:3.4-5: warning: empty character literal [-Wother]

  $ bison -Wno-deprecated
  input.yy:3.4-5: warning: empty character literal [-Wother]

  $ bison -Wnone
  (n'affiche rien)
  \end{verbatim}

  Notez que Bison active par défaut un certain nombre de catégories, dont
  \textit{deprecated} et \textit{other}.


  \subsubsection{Avertissements de dépréciation}

  A propos de ces avertissements de dépréciation, Victor avait préparé le
  terrain pour leur utilisation, en rendant les routines de rapport d'erreurs
  génériques non seulement entre erreurs et avertissements, mais également
  entre avertissements de catégories différentes. Cependant, les avertissements
  de dépréciation n'étaient jamais émis. La dépréciation n'était alors que
  documentée, et notée en commentaire dans le code de Bison. Une de mes tâches
  fut donc, pour générer les avertissements de l'exemple précédent,  de
  transformer ainsi\footnote{commit 2062d72, Thu Oct 18 18:00:51 2012} les
  \textit{scanner} et \textit{parser} de Bison-même, car c'est à ce niveau que
  les directives déprécies sont lues par le programme, et qu'il est toujours
  intéressant de gérer les choses le plus tôt possible pour s'en débarrasser
  pour la suite

  \begin{verbatim}
diff --git a/src/parse-gram.y b/src/parse-gram.y
index f0187fb..1624dde 100644
--- a/src/parse-gram.y
+++ b/src/parse-gram.y
@@ -317,7 +317,6 @@ prologue_declaration:
 | "%expect" INT                    { expected_sr_conflicts = $2; }
 | "%expect-rr" INT                 { expected_rr_conflicts = $2; }
 | "%file-prefix" STRING            { spec_file_prefix = $2; }
-| "%file-prefix" "=" STRING        { spec_file_prefix = $3; } /* deprecated */
 | "%glr-parser"
 (..)
diff --git a/src/scan-gram.l b/src/scan-gram.l
index 8e48148..95edacc 100644
--- a/src/scan-gram.l
+++ b/src/scan-gram.l
+#define DEPRECATED(Msg)                                         \
+  do {                                                          \
+    size_t i;                                                   \
+    complain (loc, Wdeprecated,                                 \
+              _("deprecated directive: %s, use %s"),            \
+              quote (yytext), quote_n (1, Msg));                \
+    scanner_cursor.column -= mbsnwidth (Msg, strlen (Msg), 0);  \
+    for (i = strlen (Msg); i != 0; --i)                         \
+      unput (Msg[i - 1]);                                       \
+  } while (0)
+
(...)
+  /* deprecated */
+  "%default"[-_]"prec"              DEPRECATED("%default-prec");
+  "%error"[-_]"verbose"             DEPRECATED("%define parse.error verbose");
+  "%expect"[-_]"rr"                 DEPRECATED("%expect-rr");
+  "%file-prefix"{eqopt}             DEPRECATED("%file-prefix");
  \end{verbatim}

  Il y a plusieurs choses intéressantes à noter, outre le fait que maintenant
  cet avertissement soit effectivement généré.

  Notez que dans le \textit{parser}, les constructions dépréciées n'étaient pas
  traitées spécialement, ni regroupées, mais juste discrètement annotées. Par
  souci de concision, je n'ai gardé qu'une seul telle ligne ci-dessus, mais il
  y en avait trois dans ce fichier. J'ai déplacé la reconnaissance de ces
  motifs un cran plus bas, dans le \textit{scanner}-même (le plus tôt, le
  mieux c'est), où neuf autres directives dépréciées se situaient, et qui elles
  n'étaient même pas marquées comme telles. Ces directives sont maintenant
  regroupées dans un paragraphe, et utilisent tous une même macro, pour
  faciliter le travail des futurs mainteneurs.

  Dans la macro, on remarque l'appel à la fonction \texttt{complain}, par
  laquelle passe tout message d'erreur ou d'avertissement, sur laquelle j'ai
  également travaillé (détaillé plus loin).

  Également intéressant, et fruit de mon travail, la présence de \texttt{unput}
  et de la soustraction sur le curseur de position: lorsqu'une directive
  invalide dépréciée est lue, on la supprime du flux et on recommence la
  lecture en ayant inséré à la place la bonne directive (du coup le problème est
  réglé pour le reste du programme, qui peut continuer sans avoir ni à gérer
  cette directive -{}- ce qui irait à l'encontre du but de la dépréciation
  -{}-, ni à contenir du code dupliqué) mais également en ayant pris soin de ne
  pas corrompre les information de position des lexèmes, indispensables aux
  facilités de correction des bugs pour l'utilisateur, ce que aurait eu lieu si
  on avait remplacé une directive dépréciée par une autre plus longue de $n$
  caractères, Bison signalant ainsi à l'utilisateur toute erreur plus loin sur
  la même ligne comme étant décalée de $n$.

  Voici par exemple à quoi ressemblent des informations de position erronées
  par cette correction de la dépréciation:

  \begin{verbatim}
input.y:13.1-14: warning: deprecated directive, use '%define parse.error
verbose' [-Wdeprecated]
 %error_verbose %error_verbose
 ^^^^^^^^^^^^^^
input.y:13.16-29: warning: deprecated directive, use '%define parse.error
verbose' [-Wdeprecated]
 %error_verbose %error_verbose
                ^^^^^^^^^^^^^^
input.y:13.11-21: error: %define variable 'parse.error' redefined
 %error_verbose %error_verbose
           ^^^^^^^^^^^
 input.y:13-6:         previous definition
 %error_verbose %error_verbose
      ^
  \end{verbatim}

  Notez le \textit{caret diagnostic} du troisième message qui souligne quelque
  chose qui ne correspond pas à l'erreur.

  Mais ce cas est en fait bien plus vicieux. Ce bug est toujours présent à ce
  jour, d'ailleurs (alors que ceux que j'évoquais précédemment ne le sont plus,
  mais ressemblaient exactement à ceci, et j'évite en trichant ainsi avec les
  exemples de multiplier les exemples) Comme la nouvelle façon de demander de
  la verbosité est de définir la variable \texttt{parse.error}, et qu'on a
  effectué cette substitution plusieurs fois, on se retrouve avec une variable
  redéfinie.  L'erreur se situe dans le code de substitution, pas dans le code
  de l'utilisateur, notre système de localisation des erreurs perd donc
  totalement les pédales et \underline{ment}. D'ailleurs, le lecteur attentif
  aura constaté que le problème de dépréciation, qui relève du \textit{warning}
  a généré une \textit{error}, c'est très gênant car cela implique que si
  l'utilisateur avait fait le choix d'invoquer Bison avec l'option
  \texttt{-Wno-deprecated}, il n'aurait pas ces avertissements pour lui mettre
  la puce à l'oreille, il aurait juste une erreur, avec une \textit{location}
  \underline{fausse} (ce qui aurait été le cas également avec une erreur
  présente dans le code de l'utilisateur, mais au moins il aurait eu une chance
  de l'y trouver alors que là elle n'existe juste pas).

  Le lecteur vraiment attentif, lui, aura remarqué le dernier message, qui lui
  commence différemment des autres: ni par \textit{error}, ni par
  \textit{warning}. Il s'agit d'une information de contexte.

  \subsubsection{Informations de contexte, et préfixage}

  Les compilateurs fournissent souvent à l'utilisateur des informations
  supplémentaires concernant les erreurs, pour aider l'utilisateur. Voici un
  exemple avec gcc-4.7\footnote{%
  http://gcc.gnu.org/wiki/ClangDiagnosticsComparison}:

  \begin{verbatim}
  deduce.cc: In function 'void g()':
  deduce.cc:6:10: error: no matching function for call to 'f(A&)'
  deduce.cc:6:10: note: candidate is:
  deduce.cc:1:24: note: template<class T> void f(typename T::type)
  deduce.cc:1:24: note:   template argument deduction/substitution failed:
  deduce.cc: In substitution of 'template<class T> void f(typename T::type)
  [with T = A]':
  deduce.cc:6:10:   required from here
  deduce.cc:1:24: error: no type named 'type' in 'struct A'
  \end{verbatim}

  Il y a trois type de messages dans cet affichage qui ne sont pas des erreurs,
  mais qui sont simplement des indications supplémentaires.

  \begin{itemize}
    \item Le premier, \og \textit{In function `void g()'} \fg permet de
      localiser l'erreur d'une façon plus significative pour l'utilisateur. Il
      n'y a pas vraiment de situation dans Bison où l'on aurait matière à
      préciser quelque chose de genre.
    \item Le deuxième, \og \textit{deduce.cc:1:24: note: template<class T> void
      f(typename T::type)} \fg ce sont les messages qui commencent par
      \textit{note}, et qui sont des précisions complémentaires, souvent des
      indices quant à des façons de résoudre le problème. Là encore, Bison n'a
      pas grand chose de très intéressant à ajouter, les erreurs elles-mêmes
      étant généralement plutôt explicites.
    \item Enfin, la ligne qui va nous intéresser est celle qui lit \og
      \textit{deduce.cc:6:10:   required from here}\fg. Le message qui précède
      fait référence à plusieurs \textit{location}, or il est d'usage de donner
      celles-ci avec ce format très particulier \texttt{fichier:ligne:colonne}
      en début de ligne, il est donc naturel de donner les \textit{location}
      supplémentaires via des messages additionnels. Le corps de ces messages
      est indenté par rapport aux précédents.
  \end{itemize}

  Dans Bison, le cas des erreurs faisant référence à un bout du code situé en
  amont est fréquent. C'est par exemple le cas des variables (re)définies avec
  \texttt{\%define}, ou des tokens dont le numéro est en conflit, comme ici:

  \begin{verbatim}
r.y:10.10-22: error: user token number 112 redeclaration for HEX_1
r.y:9.8-16:       previous declaration for DECIMAL_1
  \end{verbatim}

  Ce second message est indenté, dans l'esprit de la remarque précédente, pour
  mettre en évidence la nature contextuelle de l'information.

  Cette indentation est un produit de mon travail. Auparavant, une routine
  existait pour afficher un message indenté: il s'agit de
  \texttt{complain\_at}.  Cette routine ne servait malheureusement que pour
  certains messages, celui ci-dessus par exemple utilisait la simple procédure
  \texttt{complain}, et n'était aucunement indentée. Voici un exemple des
  lègères corrections qui furent nécessaire à la bonne mise en forme de ces
  messages\footnote{commit cbaea01, Wed Sep 26 11:49:19 2012}:

  \begin{verbatim}
 static void
 semantic_type_redeclaration (semantic_type *s, const char *what, location first,
                              location second)
 {
-  complain_at (second, _("%s redeclaration for <%s>"), what, s->tag);
-  complain_at (first, _("previous declaration"));
+  unsigned i = 0;
+  complain_at_indent (second, &i, _("%s redeclaration for <%s>"), what, s->tag);
+  i += SUB_INDENT;
+  complain_at_indent (first, &i, _("previous declaration"));
 }
  \end{verbatim}

  Le lecteur assidu aura noté la présence d'une fonction \og \texttt{\_} \fg,
  qui était également présente dans le précédent extrait de code. Il s'agit en
  fait d'un \textit{wrapper} autour de la fonction de traduction\footnote{%
  http://translationproject.org/html/welcome.html} \texttt{gettext}, définit
  comme suit:

  \begin{verbatim}
  src/system.h: # define \_(Msgid)  gettext (Msgid)
  \end{verbatim}

  Comme les messages sont traduit selon une collection de motifs,, il faut bien
  faire attention à ne pas les découper n'importe comment, sinon on rend le
  travail des traducteurs difficile. A propos des traductions délicates, voici
  un exemple de message étrangement traduit:

  \begin{verbatim}
  $ LC_ALL=en_US.utf8 bison -Wdeprecated t.y
  t.y:5.1: error: rule given for a, which is a token
  $ LC_ALL=fr_FR.utf8 bison -Wdeprecated t.y
  t.y:5.1: erreur: la règle pour a, qui est un terminal
  \end{verbatim}

  Pour en revenir à notre exemple, on peut s'intéresser à l'implémentation de
  cette fonction \texttt{complain\_at}. Comme on peut le voir, on appelle aussi
  cette fonction pour la partie non-indentée du message. En fait, on initialise
  un entier à zéro, et on le passe à notre fonction par référence afin qu'elle
  soit modifiée. Lorsque cette valeur est nulle, la fonction se comporte comme
  la simple \texttt{complain}, au détail près qu'elle modifie cette valeur pour
  y stocker la colonne courante du début du message. Lors du second appel, la
  valeur n'est plus nulle, et \texttt{complain\_at} a un nouveau comportement:
  elle affiche le corps du message  à la colonne correspondant à la valeur
  stockée dans la variable. L'incrément manuel de cette valeur entre les deux
  appels correspond donc au changement de niveau d'indentation. Cette interface
  peu sembler un peu compliquée au premier abord: on aurait pu se contenter
  d'ajouter un Booléen indiquant le corps du message était à indenter ou non.
  Ce que l'on gagne avec cette méthode est la gestion des niveaux d'indentation
  imbriqués, au cas où un jour où en aurait l'utilité.

  Une faiblesse de cette approche (qui aurait également été présente dans la
  version plus simple que je viens de suggérer) est que l'on part du postulat
  que la partie gauche du second message (la \textit{location}) aura la même
  taille que celle du premier message. C'est généralement vrai, la différence
  potentielle se limitant généralement à quelques colonnes, et généralement
  dans le sens négatif (c'est à dire que la seconde est plus courte que la
  première, conséquence directe du fait que ce second message fait à priori
  référence à une déclaration précédente, et donc avec un numéro de ligne et/ou
  colonne inférieur --donc à potentiellement moins de chiffres), mais dans le
  cas contraire, la différence empièterait sur l'indentation. Exemple adapté du
  précédent:

  \begin{verbatim}
r.y:1.1-2: error: user token number 112 redeclaration for HEX_1
r.y:1000.18-26:previous declaration for DECIMAL_1
  \end{verbatim}

  Notez que le \textit{previous:} est à la même position relativement au
  \textit{error:}, mais que du fait du changement de taille de la
  \textit{location} l'indentation est maintenant absente.

  Ce cas ne devrait jamais se produire (la seule situation plausible étant non
  pas une différence dans les numéros de ligne mais de colonne, or on imagine
  difficilement un scénario raisonnable à mille colonnes), mais il existe une
  façon de le gérer\footnote{Déjà évoquée sur la mailing-liste:
  http://lists.gnu.org/archive/html/bison-patches/2009-09/msg00086.html}: il
  faudrait utiliser un \textit{buffer} pour stocker les messages, en y insérant
  des marqueurs là où on souhaite changer le niveau d'indentation, et ensuite
  effectuer une deuxième passe pour effectuer les insertions de blancs.

  Enfin, dernier point d'intérêt sur ce sujet: le préfixe des erreurs. En
  effet, le lecteur a très certainement constaté que nos messages d'erreurs
  commencent par \textit{error:} tandis que les avertissement, eux, commencent
  par \textit{warning:}. C'est explicite, et ça semble très naturel. Pourtant,
  ce sont des additions récentes: Victor a préfixé les avertissements, et c'est
  moi même qui ai pris la responsabilité de préfixer les erreurs.

  \subsubsection{\textit{warnings as errors}}


  Une fonctionnalité remarquable de GCC est d'activer le traitement des
  avertissements en erreurs pour certaines catégories. Par exemple, avec
  l'option \texttt{-Werror=unused-argument}, les arguments d'une fonction qui
  ne sont pas utilisés par celle-ci sont traités comme des erreurs.

  Maintenant que Bison dispose de catégories de d'avertissements, il était
  devenu aisé d'implémenter ce comportement, et ce fut en fait la première
  tâche qui m'avait été assignée (bien que j'ai été un peu distrait en cours de
  route par d'autres considérations d'ergonomie sur les erreurs, détaillées
  précédemment).

  L'option \texttt{-Werror}, permettant de promouvoir la totalité des
  avertissements en erreurs, existait déjà. En fait, c'était un hack: cette
  option active une fausse catégorie \textit{error} d'avertissements qui sert,
  dans la routine de génération des avertissements et erreurs, à promouvoir
  ceux-ci en ces dernières lorsqu'elle est activée. Ceci n'offre aucune
  flexibilité, c'est donc une impasse. Il a fallu repenser la façon de faire.

  Une grande contrainte dans l'ajout du support d'une nouvelle option dans la
  ligne de commande est que l'on veut au maximum s'intégrer dans les fonctions
  de reconnaissance d'arguments actuelles. En l'occurrence, Bison dispose de
  routines génériques et assez élégantes pour reconnaitre des consructions de
  la forme \texttt{-Wno-deprecated,other,no-yacc -{}-report=state,solved} pour
  factoriser \texttt{-Wno-deprecated, -Wother -Wno-yacc -{}-report=state
  -{}-report=solved}. On note au passage le support des variantes \texttt{no-}
  de chaque catégorie, qui se fait sans la moindre duplication de code.

  Voici un extrait de la fonction \texttt{flags\_argmatch} telle qu'elle
  existait à mon arrivée:

  \begin{verbatim}
      args = strtok (args, ",");
      while (args)
        {
          int no = strncmp (args, "no-", 3) == 0 ? 3 : 0;
          int value = XARGMATCH (option, args + no, keys, values);

          /* operations sur warn_flags ici */
  \end{verbatim}

  Selon la valeur de \texttt{no}, le traitement sur la variable globale
  \texttt{warn\_flags} stockant (sous forme de bits) les \textit{flags} activés
  est différent: il peut s'agit d'une mise d'un bit à 1, ou à 0.

  J'ai décidé de m'inspirer de cette façon de faire. J'ai introduit une
  nouvelle globale, un véritable miroir de \texttt{warn\_flags}, que j'ai nommé
  \texttt{error\_flags}, et qui stocke de la même façon l'information \og est
  ce que cet avertissement est à traiter en erreur? \fg. Du coup, l'unique
  différence entre les façons de traiter \texttt{-W[no-]category} et
  \texttt{-W[no-]error=category} est la variable à modifier: dans un cas, on
  veut modifier la reconnaissance d'une catégorie, dans l'autre cas on veut
  activer son passage en erreur.

  Le résultat se voit dans ces quelques lignes\footnote{%
  commit 20964c3, Mon Oct 1 15:01:03 2012}:

  \begin{verbatim}
    for (args = strtok (args, ","); args; args = strtok (NULL, ","))
      {
        size_t no = STRPREFIX_LIT ("no-", args) ? 3 : 0;
        size_t err = STRPREFIX_LIT ("error", args + no) ? 5 : 0;

        flag_argmatch (option, keys,
                       values, all, err ? &errors_flag : flags,
                       args, no, err);
      }
  \end{verbatim}

  Ce bout de code constitue en fait le corps de la nouvelle fonction
  \texttt{flags\_argmatch}. Les opérations sur les variables globales ont été
  déplacées dans une nouvelle fonction, pour une meilleur segmentation du code.

  Voici ces fameuses opérations, avec des explications pas à pas:

  \begin{itemize}
    \item Première partie de l'alternative (\texttt{-W[no-]category}): ces
      opérations font de simples opérations bits à bits: un masque
      (\texttt{\&=$\sim$}) dans le cas du \texttt{no-}, afin de
      désactiver le bit courant tout en préservant l'état des autres bits; un
      OU (\texttt{|=}) dans le cas normal, pour mettre le bit en question à un.


  \begin{verbatim}
    if (value)
      {
        if (no)
          *flags &= ~value;
        else
          {
  \end{verbatim}

    \item Il y a une action en plus à effectuer dans le
      cas où on fait du \texttt{error=}. En effet, par choix (cohérent avec
      celui de GCC), on veut que \texttt{-Werror=category} ne fasse pas
      qu'activer la promotion de cette catégorie en erreur, mais également
      qu'il active les \textit{warnings} de cette catégorie. Sinon,
      l'utilisateur se retrouve à devoir spécifier deux fois ce nom de
      catégorie: une fois pour le \texttt{-W}, et une fois pour le
      \texttt{-Werror=}. Ainsi, il faut travailler sur les deux variables en
      même temps.

  \begin{verbatim}
            if (err)
              warnings_flag |= value;
            *flags |= value;
          }
      }
  \end{verbatim}

    \item Deuxième partie de l'alternative (\texttt{-W[no-]none}): cette valeur
      est spéciale: plutôt que signifier la modification d'une catégorie
      précise, elle affecte au contraire toutes les autres (et éventuellement
      elle-même, cette catégorie n'ayant aucune utilité en soi pour le reste
      des évènements): c'est à dire que lorsqu'on \textit{set} \texttt{none},
      en fait ce qu'on veut c'est \textit{reset} tout le reste, d'où le code
      qui reprend le cas "usuel", mais inversé. Notons que la catégorie
      \texttt{all} est gérée encore différemment: c'est une catégorie un peu
      comme les autres, sauf que sa valeur dans l'énumération C des catégories
      (qui sont des bits: 1, 2, 4, 8, etc.) est \texttt{$\sim$all}, c'est à
      dire une valeur qui correspond "magiquement" à l'union de toutes les
      autres valeurs possibles de l'énumération.

  \begin{verbatim}
    else
      {
        if (no ? !err : err)
          *flags |= all;
        else
          *flags &= ~all;
      }
  \end{verbatim}


    \item Le mystérieux ternaire code le comportement suivant: de même que
      \texttt{-Wno-none} signifie \texttt{-Wall},
      \texttt{-Wno-error=none}\footnote{%
        Le lecteur qui a du mal à s'y retrouver peut imaginer ceci: on précise
        que, pour aucun avertissement, il ne faut pas promouvoir ceux-ci en
        erreur; c'est à dire qu'on donne une précision qui ne s'applique à
      rien, et qui n'a donc aucune importance.}, signifie
      \texttt{-Werror=all}\footnote{Il faut bien comprendre que le "error=" ne
        change pour ainsi dire rien, si ce n'est la variable courante: on peut
        donc "simplifier" ce terme de l'option, et le résultat devient
      immédiat, puisqu'on vient de rappeler que no-none est équivalent à all.}
      ce qui est faux. L'usage de \texttt{-Wno-error=category} n'activant pas
      implicitement le
      \texttt{-Werror} des autres catégories, il n'y a aucune raison pour que
      le \texttt{-Wno-error=none} le fasse.
    \item Les constructions fantaisistes à la \texttt{-Wno-error=no-category}
      sont impossibles, de par le fonctionnement du \textit{wrapper}
      \texttt{flags\_argmatch}.
  \end{itemize}


  Résultat final:


  \begin{verbatim}
  $ bison -Werror=deprecated
  input.yy:2.9-15: error: deprecated directive: ‘%define variant’, use ‘%define
  api.value.type variant’ [-Werror=deprecated]
  input.yy:3.4-5: warning: empty character literal [-Wother]
  \end{verbatim}

  \subsubsection{\textit{caret diagnostics}}

  Une caractéristique très appréciée de Clang par la communauté est sa façon de
  rapporter les erreurs, en adjoignant à chacune une ligne du code source
  fautif correspondant, en soulignant l'endroit de l'erreur. C'est ce qu'on
  appelle des \textit{caret diagnostics}, ou encore des \textit{caret errors}.

  Ils sont introduits dans gcc-4.8 également. Ca ressemble à ceci\footnote{%
  http://gcc.gnu.org/wiki/ClangDiagnosticsComparison}:

  \begin{verbatim}
$ gcc-4.8 -fsyntax-only t.c

t.c: In function 'f':
t.c:6:11: error: invalid operands to binary / (have '__m128' and 'const int *')
   myvec[1]/P;
           ^
$ clang-3.1 -fsyntax-only t.c

t.c:6:11: error: can't convert between vector values of different size ('__m128'
and 'int const *')
  myvec[1]/P;
  ~~~~~~~~^~
  \end{verbatim}

  Bison ne dispose pas actuellement d'assez d'informations pour un affichage
  aussi évolué que celui de Clang, mais nos \textit{location} sont tout à fait
  suffisantes pour imiter le comportement de GCC\@. En fait, comme l'exemple le
  montre, GCC se contente souvent de montrer la colonne de début du lieux
  intéressant, tandis que dans Bison nous avons des informations un peu plus
  riches: on garde trace de la colonne (et de la ligne) de début, mais aussi de
  fin. Par exemple, dans l'exemple suivant, on voit des \textit{location} d'une
  largeur de quatre colonnes.

  La question s'est posée de savoir comment optimiser la routine d'affichage de
  ces \textit{carets}:
  \begin{verbatim}
$ bison -fcaret input.y

input.y:10.13-17: error: %destructor redeclaration for foo
 %destructor {baz} "foo"
             ^^^^^
input.y:5.13-17:      previous declaration
 %destructor {bar} foo
             ^^^^^
\end{verbatim}

  On voit que nous avons fait le choix de souligner l'intégralité du lieux, et
  pas juste la première colonne. On aurait pu vouloir tenter une imitation de
  Clang, et utiliser \verb|^~~~|, mais comme on aurait jamais pu
  mettre l'accent sur autre chose que le premier caractère, l'intérêt n'était
  pas flagrant.


  \subsubsection{La suite de tests}

  \subsection{Visualisation graphique}
  \subsubsection{Affichage des réductions}
  \subsubsection{Adaptation à la production via XML}

  \subsection{Squelettes}
  \subsubsection{Introduction d'une nouvelle forme de pureté}
  \subsubsection{Modifications mineures de glr.cc}
  \subsubsection{Changements de lalr1.cc}
  \subsubsection{Réécriture des symboles}

  \cleardoublepage
  \section{Conclusion}

  \cleardoublepage
  \section{Annexes}

  \subsection{git shortlog --author=ranquet}
  \begin{adjustwidth}{-2cm}{-2cm}
    %\include{commits}
  \end{adjustwidth}

  \cleardoublepage
  \cleardoublepage
\end{document}

